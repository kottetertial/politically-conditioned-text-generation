{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "political_views_nlg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen_data = pd.read_csv(\"item.csv\", header=None, names=[\"Label\", \"Content\"])\n",
    "gen_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perplexity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install spacy ftfy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt')\n",
    "model.eval()\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def score(sentence):\n",
    "    tokenize_input = tokenizer.tokenize(sentence)\n",
    "    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    loss = model(tensor_input, lm_labels=tensor_input)\n",
    "    return math.exp(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "liberal_perplexity = np.array([score(i) for i in gen_data[gen_data[\"Label\"] == \"Liberal\"][\"Content\"]])\n",
    "conservative_perplexity = np.array([score(i) for i in gen_data[gen_data[\"Label\"] == \"Conservative\"][\"Content\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(liberal_perplexity.mean(), 2), round(conservative_perplexity.mean(), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(np.array([score(i) for i in gen_data[\"Content\"]]).mean(), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_ngram(sentences, n):\n",
    "    \"\"\"\n",
    "    Count the number of unique n-grams\n",
    "    :param sentences: list, a list of responses\n",
    "    :param n: int, n-gram\n",
    "    :return: the number of unique n-grams in sentences\n",
    "    \"\"\"\n",
    "    if len(sentences) == 0:\n",
    "        print(\"ERROR, eval_distinct get empty input\")\n",
    "        return\n",
    "\n",
    "    if type(sentences[0]) != list:\n",
    "        print(\"ERROR, eval_distinct takes in a list of <class 'list'>, get a list of {} instead\".format(\n",
    "            type(sentences[0])))\n",
    "        return\n",
    "\n",
    "    ngram = set()\n",
    "    for resp in sentences:\n",
    "        if len(resp) < n:\n",
    "            continue\n",
    "        for i in range(len(resp) - n + 1):\n",
    "            ngram.add(' '.join(resp[i: i + n]))\n",
    "    return len(ngram)\n",
    "\n",
    "\n",
    "def eval_distinct(sentences):\n",
    "    \"\"\"\n",
    "    compute distinct score for the sentences\n",
    "    :param sentences: list, a list of hyps responses\n",
    "    :return: average distinct score for 1, 2-gram\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = [list(map(str, tokenizer.encode(sent))) for sent in sentences]\n",
    "\n",
    "    if len(sentences) == 0:\n",
    "        print(\"ERROR, eval_distinct get empty input\")\n",
    "        return\n",
    "\n",
    "    if type(sentences[0]) != list:\n",
    "        print(\"ERROR, eval_distinct takes in a list of <class 'list'>, get a list of {} instead\".format(\n",
    "            type(sentences[0])))\n",
    "        return\n",
    "\n",
    "    sentences = [(' '.join(i)).split() for i in sentences]\n",
    "    num_tokens = sum([len(i) for i in sentences])\n",
    "    dist1 = count_ngram(sentences, 1) / float(num_tokens)\n",
    "    dist2 = count_ngram(sentences, 2) / float(num_tokens)\n",
    "    dist3 = count_ngram(sentences, 3) / float(num_tokens)\n",
    "\n",
    "    return round(dist1, 2), round(dist2, 2), round(dist3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_distinct(gen_data[gen_data[\"Label\"] == \"Conservative\"][\"Content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_distinct(gen_data[gen_data[\"Label\"] == \"Liberal\"][\"Content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_distinct(gen_data[\"Content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}